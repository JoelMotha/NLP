{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Select first 100 samples\n",
    "df = df.head(100)\n",
    "\n",
    "# Convert labels to binary values\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "\n",
    "# 1️⃣ Data Distribution (Positive vs Negative Reviews)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=df[\"sentiment\"].map({1: \"Positive\", 0: \"Negative\"}), palette=\"coolwarm\")\n",
    "plt.title(\"Distribution of Sentiments\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Text preprocessing function\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(clean_text)\n",
    "\n",
    "# 2️⃣ Word Cloud for Most Common Words\n",
    "text_data = \" \".join(df[\"review\"])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text_data)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Most Common Words in Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"review\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"review\"])\n",
    "\n",
    "# Determine appropriate padding length\n",
    "max_length = int(np.percentile([len(seq) for seq in sequences], 90))\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=\"post\")\n",
    "\n",
    "# Train-Test Split (80-20)\n",
    "train_size = int(0.8 * len(padded_sequences))\n",
    "X_train, X_test = padded_sequences[:train_size], padded_sequences[train_size:]\n",
    "y_train, y_test = df[\"sentiment\"][:train_size], df[\"sentiment\"][train_size:]\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=100, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=4, callbacks=[early_stopping])\n",
    "\n",
    "# 3️⃣ Training & Validation Accuracy/Loss Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\", marker=\"o\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\", marker=\"o\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\", marker=\"o\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "pred_labels = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "# 4️⃣ Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, pred_labels)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, pred_labels))\n",
    "\n",
    "# Print Predictions\n",
    "for review, pred in zip(df[\"review\"][train_size:], pred_labels):\n",
    "    sentiment = \"positive\" if pred == 1 else \"negative\"\n",
    "    print(f\"Review: {review[:100]}...\\nPredicted Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute Accuracy Score\n",
    "accuracy = accuracy_score(y_test, pred_labels)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
