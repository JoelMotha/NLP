{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN model...\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.1125 - loss: 3.0706 - val_accuracy: 0.5000 - val_loss: 2.9354\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5208 - loss: 2.8672 - val_accuracy: 0.6250 - val_loss: 2.7469\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6417 - loss: 2.6759 - val_accuracy: 0.6250 - val_loss: 2.4930\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6417 - loss: 2.3072 - val_accuracy: 0.6250 - val_loss: 2.0749\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5083 - loss: 2.0628 - val_accuracy: 0.6250 - val_loss: 1.7774\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5042 - loss: 1.8434 - val_accuracy: 0.6250 - val_loss: 1.6709\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7333 - loss: 1.4248 - val_accuracy: 0.6250 - val_loss: 1.6320\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7875 - loss: 1.4196 - val_accuracy: 0.6250 - val_loss: 1.6350\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7958 - loss: 1.2738 - val_accuracy: 0.6250 - val_loss: 1.6429\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8375 - loss: 1.0829 - val_accuracy: 0.6250 - val_loss: 1.6408\n",
      "Training LSTM model...\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.0833 - loss: 3.0876 - val_accuracy: 0.5000 - val_loss: 3.0666\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5125 - loss: 3.0447 - val_accuracy: 0.6250 - val_loss: 3.0179\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3583 - loss: 3.0140 - val_accuracy: 0.6250 - val_loss: 2.9626\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3292 - loss: 2.9485 - val_accuracy: 0.6250 - val_loss: 2.8645\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4292 - loss: 2.8750 - val_accuracy: 0.6250 - val_loss: 2.7077\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4208 - loss: 2.7048 - val_accuracy: 0.6250 - val_loss: 2.4465\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3583 - loss: 2.5069 - val_accuracy: 0.6250 - val_loss: 2.1259\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4333 - loss: 2.0794 - val_accuracy: 0.6250 - val_loss: 1.9251\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5250 - loss: 2.0452 - val_accuracy: 0.6250 - val_loss: 1.8485\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3458 - loss: 2.0948 - val_accuracy: 0.6250 - val_loss: 1.8598\n",
      "Training Bi-LSTM model...\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.1333 - loss: 3.0858 - val_accuracy: 0.6250 - val_loss: 3.0432\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3542 - loss: 3.0305 - val_accuracy: 0.6250 - val_loss: 2.9682\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2875 - loss: 2.9671 - val_accuracy: 0.6250 - val_loss: 2.8611\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1917 - loss: 2.8930 - val_accuracy: 0.6250 - val_loss: 2.7078\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3292 - loss: 2.7188 - val_accuracy: 0.6250 - val_loss: 2.4718\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3292 - loss: 2.4248 - val_accuracy: 0.6250 - val_loss: 2.1948\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3417 - loss: 2.2836 - val_accuracy: 0.6250 - val_loss: 2.0782\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5042 - loss: 1.7199 - val_accuracy: 0.6250 - val_loss: 2.0822\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4000 - loss: 1.8488 - val_accuracy: 0.6250 - val_loss: 2.1757\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4417 - loss: 2.0405 - val_accuracy: 0.6250 - val_loss: 2.3255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "BLEU Score for RNN: 6.457042061640853e-78\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "BLEU Score for LSTM: 6.457042061640853e-78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "BLEU Score for Bi-LSTM: 6.457042061640853e-78\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.0885 - loss: 3.0957 - val_accuracy: 0.1250 - val_loss: 3.1185\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7135 - loss: 2.8843 - val_accuracy: 0.1250 - val_loss: 3.1188\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8073 - loss: 2.6879 - val_accuracy: 0.2500 - val_loss: 3.1271\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8750 - loss: 2.4402 - val_accuracy: 0.2500 - val_loss: 3.1532\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8281 - loss: 2.2244 - val_accuracy: 0.2500 - val_loss: 3.2273\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 1.9900 - val_accuracy: 0.2500 - val_loss: 3.3640\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7656 - loss: 1.7162 - val_accuracy: 0.2500 - val_loss: 3.5676\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7552 - loss: 1.5692 - val_accuracy: 0.2500 - val_loss: 3.7060\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8958 - loss: 1.3607 - val_accuracy: 0.2500 - val_loss: 3.8063\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9427 - loss: 1.3060 - val_accuracy: 0.2500 - val_loss: 3.8722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "BLEU Score without Teacher Forcing: 6.457042061640853e-78\n",
      "BLEU Score with Teacher Forcing: 6.457042061640853e-78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Bidirectional\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Generate random dataset (10 records)\n",
    "data = {\n",
    "    \"english_sentence\": [\n",
    "        \"hello\", \"how are you\", \"good morning\", \"thank you\", \"what is your name\",\n",
    "        \"where are you from\", \"i love programming\", \"have a great day\", \"see you soon\", \"welcome home\"\n",
    "    ],\n",
    "    \"hindi_sentence\": [\n",
    "        \"नमस्ते\", \"आप कैसे हैं\", \"सुप्रभात\", \"धन्यवाद\", \"आपका नाम क्या है\",\n",
    "        \"आप कहाँ से हैं\", \"मुझे प्रोग्रामिंग पसंद है\", \"आपका दिन शुभ हो\", \"फिर मिलेंगे\", \"स्वागत है\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "df[\"english_sentence\"] = df[\"english_sentence\"].apply(preprocess_text)\n",
    "df[\"hindi_sentence\"] = df[\"hindi_sentence\"].apply(preprocess_text)\n",
    "\n",
    "# Tokenization\n",
    "eng_tokenizer = Tokenizer()\n",
    "hin_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(df[\"english_sentence\"])\n",
    "hin_tokenizer.fit_on_texts(df[\"hindi_sentence\"])\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
    "\n",
    "eng_sequences = eng_tokenizer.texts_to_sequences(df[\"english_sentence\"])\n",
    "hin_sequences = hin_tokenizer.texts_to_sequences(df[\"hindi_sentence\"])\n",
    "\n",
    "max_eng_len = max(len(seq) for seq in eng_sequences)\n",
    "max_hin_len = max(len(seq) for seq in hin_sequences)\n",
    "\n",
    "eng_sequences = pad_sequences(eng_sequences, maxlen=max_eng_len, padding='post')\n",
    "hin_sequences = pad_sequences(hin_sequences, maxlen=max_hin_len, padding='post')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(eng_sequences, hin_sequences, test_size=0.2)\n",
    "\n",
    "def build_model(cell_type=\"LSTM\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=eng_vocab_size, output_dim=128, input_length=max_eng_len))\n",
    "    \n",
    "    if cell_type == \"LSTM\":\n",
    "        layer = LSTM(256, return_sequences=True)\n",
    "    elif cell_type == \"RNN\":\n",
    "        layer = tf.keras.layers.SimpleRNN(256, return_sequences=True)\n",
    "    elif cell_type == \"GRU\":\n",
    "        layer = GRU(256, return_sequences=True)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid cell type\")\n",
    "    \n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(layer))\n",
    "    else:\n",
    "        model.add(layer)\n",
    "    \n",
    "    model.add(Dense(hin_vocab_size, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Training Models\n",
    "models = {\n",
    "    \"RNN\": build_model(\"RNN\"),\n",
    "    \"LSTM\": build_model(\"LSTM\"),\n",
    "    \"Bi-LSTM\": build_model(\"LSTM\", bidirectional=True)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} model...\")\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test, y_test))  # Adjusted batch size\n",
    "\n",
    "# Evaluate with BLEU Score\n",
    "def evaluate_bleu(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_texts = [np.argmax(pred, axis=1) for pred in predictions]\n",
    "    reference_texts = [[seq] for seq in y_test]\n",
    "    return corpus_bleu(reference_texts, predicted_texts)\n",
    "\n",
    "for name, model in models.items():\n",
    "    bleu = evaluate_bleu(model, X_test, y_test)\n",
    "    print(f\"BLEU Score for {name}: {bleu}\")\n",
    "\n",
    "# Implement teacher forcing\n",
    "def train_with_teacher_forcing(model, X_train, y_train):\n",
    "    y_train_shifted = np.concatenate((np.zeros((y_train.shape[0], 1)), y_train[:, :-1]), axis=1)\n",
    "    model.fit(X_train, y_train_shifted, epochs=10, batch_size=2, validation_split=0.2)  # Adjusted batch size\n",
    "    return model\n",
    "\n",
    "# Train RNN with teacher forcing\n",
    "rnn_tf_model = build_model(\"RNN\")\n",
    "rnn_tf_model = train_with_teacher_forcing(rnn_tf_model, X_train, y_train)\n",
    "\n",
    "# Evaluate translation accuracy with and without teacher forcing\n",
    "rnn_bleu = evaluate_bleu(models[\"RNN\"], X_test, y_test)\n",
    "rnn_tf_bleu = evaluate_bleu(rnn_tf_model, X_test, y_test)\n",
    "print(f\"BLEU Score without Teacher Forcing: {rnn_bleu}\")\n",
    "print(f\"BLEU Score with Teacher Forcing: {rnn_tf_bleu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
