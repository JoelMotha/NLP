{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-rDKzbV9H9F",
        "outputId": "19919690-4662-4786-ce99-b30484358022"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to C:\\Users\\mohammed\n",
            "[nltk_data]     luqmaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuKYjJhw9Ws7"
      },
      "source": [
        "Get Synonyms from WordNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmg_O_Ts6sua"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDBVbWqo89j0",
        "outputId": "f76d07bb-b64d-4022-f776-5e061c00d3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Word: cricket\n",
            "1. cricket.n.01 - leaping insect; male makes chirping noises by rubbing the forewings together\n",
            "2. cricket.n.02 - a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n",
            "3. cricket.v.01 - play cricket\n",
            "\n",
            "Word: gym\n",
            "1. gymnasium.n.02 - athletic facility equipped for sports or physical training\n",
            "\n",
            "Word: fitness\n",
            "1. fitness.n.01 - the quality of being suitable\n",
            "2. fitness.n.02 - good physical condition; being in shape or in condition\n",
            "3. seaworthiness.n.01 - fitness to traverse the seas\n",
            "4. fitness.n.04 - the quality of being qualified\n",
            "\n",
            "Word: body\n",
            "1. body.n.01 - the entire structure of an organism (an animal, plant, or human being)\n",
            "2. body.n.02 - a group of persons associated by some common tie or occupation and regarded as an entity\n",
            "3. body.n.03 - a natural object consisting of a dead animal or person\n",
            "4. body.n.04 - an individual 3-dimensional object that has mass and that is distinguishable from other objects\n",
            "5. torso.n.01 - the body excluding the head and neck and limbs\n",
            "\n",
            "Word: cardio\n"
          ]
        }
      ],
      "source": [
        "words = [\"cricket\", \"gym\", \"fitness\", \"body\", \"cardio\"]\n",
        "\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "    print(f\"\\nWord: {word}\")\n",
        "    for i, syn in enumerate(synsets[:5], start=1):\n",
        "        print(f\"{i}. {syn.name()} - {syn.definition()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTObPeFV9h1D"
      },
      "source": [
        "***Find the 3rd meaning of the word***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O35CJl9T9lOZ"
      },
      "outputs": [],
      "source": [
        "word = \"talk\"\n",
        "synsets = wordnet.synsets(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9uBYiii9pGv",
        "outputId": "96b8bed4-665b-4555-b137-1d11acedb8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3rd meaning of 'talk': the act of giving a talk to an audience\n"
          ]
        }
      ],
      "source": [
        "if len(synsets) >= 3:\n",
        "    third_meaning = synsets[2]\n",
        "    print(f\"3rd meaning of '{word}': {third_meaning.definition()}\")\n",
        "else:\n",
        "    print(f\"Less than 3 meanings found for '{word}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR5TQYnO-F35"
      },
      "source": [
        "***Extract different PoS from synonyms***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL6qYWBq-QPA",
        "outputId": "8c796e03-5c85-423e-d904-4e5ff0d8287f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nouns: ['lecture', 'talking', 'talk', 'public_lecture', 'talk_of_the_town']\n",
            "Verbs: ['verbalize', 'let_the_cat_out_of_the_bag', 'tattle', 'peach', 'verbalise', 'babble_out', 'blab_out', 'lecture', 'mouth', 'blab', 'spill_the_beans', 'babble', 'talk', 'utter', 'sing', 'speak', 'spill']\n",
            "Adjectives: []\n",
            "Adverbs: []\n"
          ]
        }
      ],
      "source": [
        "def get_synonyms_by_pos(word, pos):\n",
        "    synsets = wordnet.synsets(word, pos=pos)\n",
        "    synonyms = set()\n",
        "    for syn in synsets:\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return list(synonyms)\n",
        "\n",
        "word = \"talk\"\n",
        "print(\"Nouns:\", get_synonyms_by_pos(word, wordnet.NOUN))\n",
        "print(\"Verbs:\", get_synonyms_by_pos(word, wordnet.VERB))\n",
        "print(\"Adjectives:\", get_synonyms_by_pos(word, wordnet.ADJ))\n",
        "print(\"Adverbs:\", get_synonyms_by_pos(word, wordnet.ADV))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJiyP84n-phx"
      },
      "source": [
        "***Extract the definition of the word***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTyVYR7q-wji",
        "outputId": "74116f4a-65a1-4a21-f48b-d5af3adc0c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Definition of 'strong': having strength or power greater than average or expected\n"
          ]
        }
      ],
      "source": [
        "word = \"strong\"\n",
        "synsets = wordnet.synsets(word)\n",
        "\n",
        "if synsets:\n",
        "    print(f\"Definition of '{word}': {synsets[0].definition()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Fn_USc_CH1"
      },
      "source": [
        "***Get Antonyms from WordNet***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y-O0PCl0_MaG"
      },
      "outputs": [],
      "source": [
        "def get_antonyms(word):\n",
        "    antonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.antonyms():\n",
        "                antonyms.add(lemma.antonyms()[0].name())\n",
        "    return list(antonyms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJZC1j6W_Xie",
        "outputId": "52b5456b-6098-415a-c85b-5e06e17bcc84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Antonyms of 'happy': ['unhappy']\n"
          ]
        }
      ],
      "source": [
        "word = \"happy\"\n",
        "print(f\"Antonyms of '{word}': {get_antonyms(word)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQaA2rxv_aJS",
        "outputId": "19cf0a75-c636-4872-90ce-cc67d4dc0e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Antonyms of 'talk': ['keep_quiet']\n"
          ]
        }
      ],
      "source": [
        "word = \"talk\"\n",
        "print(f\"Antonyms of '{word}': {get_antonyms(word)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8s6e7T1_eA2",
        "outputId": "ec5b8edb-ef23-49f2-9b10-4ae3dca11eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Antonyms of 'Good': ['ill', 'evilness', 'evil', 'bad', 'badness']\n"
          ]
        }
      ],
      "source": [
        "word = \"Good\"\n",
        "print(f\"Antonyms of '{word}': {get_antonyms(word)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl72MdAL_1XY"
      },
      "source": [
        "***Lemmatizing words using WordNet***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoa2xjOK_5bJ",
        "outputId": "9ebd5000-b5a4-4c19-f981-ca39a6e46fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lemmatized 'running': run\n",
            "Lemmatized 'speaking': speak\n",
            "Lemmatized 'stronger': stronger\n",
            "Lemmatized 'happiest': happiest\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"speaking\", \"stronger\", \"happiest\"]\n",
        "\n",
        "for word in words:\n",
        "    print(f\"Lemmatized '{word}': {lemmatizer.lemmatize(word, wordnet.VERB)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qL7Dg8LAIby"
      },
      "source": [
        "***Differentiate Stemming and Lemmatizing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHoGfNofAc_J",
        "outputId": "160246ac-4612-427d-875e-de5292a45011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word | Stemming | Lemmatizing\n",
            "running | run | run\n",
            "talked | talk | talk\n",
            "happily | happili | happily\n",
            "strongest | strongest | strongest\n",
            "flies | fli | fly\n",
            "studies | studi | study\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"talked\", \"happily\", \"strongest\",\"flies\",\"studies\"]\n",
        "\n",
        "print(\"Word | Stemming | Lemmatizing\")\n",
        "for word in words:\n",
        "    print(f\"{word} | {stemmer.stem(word)} | {lemmatizer.lemmatize(word, wordnet.VERB)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ko79cAA9li"
      },
      "source": [
        "***PoS Tagging***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLruBpvWEp8-",
        "outputId": "dda48bfb-3c8d-49e4-9fea-3a44e5497abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS Tagging:\n",
            "She - PRON\n",
            "happily - ADV\n",
            "runs - VERB\n",
            "to - ADP\n",
            "the - DET\n",
            "bright - ADJ\n",
            "and - CCONJ\n",
            "strong - ADJ\n",
            "tower - NOUN\n",
            ". - PUNCT\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sentence = \"She happily runs to the bright and strong tower.\"\n",
        "\n",
        "doc = nlp(sentence)\n",
        "print(\"POS Tagging:\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text} - {token.pos_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtCpkg0CBzO7"
      },
      "source": [
        "***Named Entity Recognition (NER)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEIAmAinB5rM",
        "outputId": "3c5ac653-6209-4e1d-d6b7-6e05707ab74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Named Entities:\n",
            "Albert Einstein - PERSON\n",
            "Germany - GPE\n",
            "Princeton University - ORG\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"Albert Einstein was born in Germany and worked at Princeton University.\"\n",
        "\n",
        "doc = nlp(text)\n",
        "print(\"Named Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} - {ent.label_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KESttokGCNQv"
      },
      "source": [
        "***Dependency & Constituency Parsing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQQx5aD4Dfjo",
        "outputId": "5a2aea79-3e45-4958-f252-ba96a765041e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting benepar\n",
            "  Downloading benepar-0.2.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: nltk>=3.2 in c:\\python312\\lib\\site-packages (from benepar) (3.9.1)\n",
            "Requirement already satisfied: spacy>=2.0.9 in c:\\python312\\lib\\site-packages (from benepar) (3.8.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\python312\\lib\\site-packages (from benepar) (2.6.0)\n",
            "Collecting torch-struct>=0.5 (from benepar)\n",
            "  Downloading torch_struct-0.5-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in c:\\python312\\lib\\site-packages (from benepar) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.2.2 in c:\\python312\\lib\\site-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (4.48.2)\n",
            "Requirement already satisfied: protobuf in c:\\python312\\lib\\site-packages (from benepar) (5.29.1)\n",
            "Collecting sentencepiece>=0.1.91 (from benepar)\n",
            "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: click in c:\\python312\\lib\\site-packages (from nltk>=3.2->benepar) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk>=3.2->benepar) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\python312\\lib\\site-packages (from nltk>=3.2->benepar) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from nltk>=3.2->benepar) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (3.1.5)\n",
            "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (75.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\mohammed luqmaan\\appdata\\roaming\\python\\python312\\site-packages (from spacy>=2.0.9->benepar) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\python312\\lib\\site-packages (from spacy>=2.0.9->benepar) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\python312\\lib\\site-packages (from tokenizers>=0.9.4->benepar) (0.28.1)\n",
            "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch>=1.6.0->benepar) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python312\\lib\\site-packages (from torch>=1.6.0->benepar) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch>=1.6.0->benepar) (3.4.2)\n",
            "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch>=1.6.0->benepar) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch>=1.6.0->benepar) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->benepar) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (0.5.2)\n",
            "Collecting accelerate>=0.26.0 (from transformers[tokenizers,torch]>=4.2.2->benepar)\n",
            "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: psutil in c:\\users\\mohammed luqmaan\\appdata\\roaming\\python\\python312\\site-packages (from accelerate>=0.26.0->transformers[tokenizers,torch]>=4.2.2->benepar) (6.0.0)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2024.8.30)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.9->benepar) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.9->benepar) (0.1.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\mohammed luqmaan\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->nltk>=3.2->benepar) (0.4.6)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->spacy>=2.0.9->benepar) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mohammed luqmaan\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (2.18.0)\n",
            "Requirement already satisfied: wrapt in c:\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (0.1.2)\n",
            "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
            "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
            "   ---------- ----------------------------- 262.1/992.0 kB ? eta -:--:--\n",
            "   ---------- ----------------------------- 262.1/992.0 kB ? eta -:--:--\n",
            "   -------------------- ----------------- 524.3/992.0 kB 598.5 kB/s eta 0:00:01\n",
            "   -------------------- ----------------- 524.3/992.0 kB 598.5 kB/s eta 0:00:01\n",
            "   ------------------------------ ------- 786.4/992.0 kB 644.9 kB/s eta 0:00:01\n",
            "   -------------------------------------- 992.0/992.0 kB 707.9 kB/s eta 0:00:00\n",
            "Downloading torch_struct-0.5-py3-none-any.whl (34 kB)\n",
            "Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py): started\n",
            "  Building wheel for benepar (setup.py): finished with status 'done'\n",
            "  Created wheel for benepar: filename=benepar-0.2.0-py3-none-any.whl size=37660 sha256=392c9acf6fe2f5c55da410eb4d5beb2bb5fecba14b1c750cf78c7ac2346bb9a7\n",
            "  Stored in directory: c:\\users\\mohammed luqmaan\\appdata\\local\\pip\\cache\\wheels\\9b\\84\\c1\\f2ac877f519e2864e7dfe52a1c17fe5cdd50819cb8d1f1945f\n",
            "Successfully built benepar\n",
            "Installing collected packages: sentencepiece, torch-struct, accelerate, benepar\n",
            "Successfully installed accelerate-1.3.0 benepar-0.2.0 sentencepiece-0.2.0 torch-struct-0.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install benepar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne2hvcRjDnos",
        "outputId": "ecda7eb7-a2fe-4c38-83c3-1d14b1a70c93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package benepar_en3 to C:\\Users\\mohammed\n",
            "[nltk_data]     luqmaan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping models\\benepar_en3.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import benepar\n",
        "benepar.download('benepar_en3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "ywGPJE9DCbSp",
        "outputId": "5f1f6738-597a-49a2-d114-4c1254bff9ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "c:\\Python312\\Lib\\site-packages\\torch\\distributions\\distribution.py:56: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependency Parsing:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4c8bcd3c8fbc414da46d9690d0651e38-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">bright</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">student</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">talks</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">happily</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">about</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">science.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-4c8bcd3c8fbc414da46d9690d0651e38-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Constituency Parsing :\n",
            "(S (NP (DT The) (JJ bright) (NN student)) (VP (VBZ talks) (ADVP (RB happily)) (PP (IN about) (NP (NN science)))) (. .))\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import benepar\n",
        "\n",
        "if \"benepar\" not in nlp.pipe_names:\n",
        "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
        "\n",
        "text = \"The bright student talks happily about science.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"Dependency Parsing:\")\n",
        "spacy.displacy.render(doc, style=\"dep\", jupyter=True)\n",
        "\n",
        "print(\"Constituency Parsing :\")\n",
        "for sent in doc.sents:\n",
        "    print(sent._.parse_string)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
